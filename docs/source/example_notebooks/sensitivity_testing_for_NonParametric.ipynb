{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bbaacaa",
   "metadata": {},
   "source": [
    "# Sensitivity analysis for non-parametric causal estimators\n",
    "Sensitivity analysis helps us study how robust an estimated effect is when the assumption of no unobserved confounding is violated. That is, how much bias did we introduce in our estimate by omitting  an (unobserved) confounder? Known as the \n",
    "*omitted variable bias (OVB)*, it gives us a measure of how the inclusion of an omitted common cause (confounder) changes the estimated effect. \n",
    "\n",
    "This notebook shows how to estimate the OVB for general, non-parametric causal estimators. For gaining intuition, we suggest going through an introductory notebook that describes how to estimate OVB for a a linear estimator: [Sensitivity analysis for linear estimators](https://github.com/py-why/dowhy/blob/master/docs/source/example_notebooks/sensitivity_analysis_testing.ipynb). To recap, in that notebook, we saw how the OVB depended on linear partial R^2 values and used this insight to compute the adjusted estimate values depending on the relative strength of the confounder with the outcome and treatment. We now generalize the technique using the non-parametric partial R^2 and Reisz representers.<br>\n",
    "\n",
    "\n",
    "### Key definitions\n",
    "**Non-parametric R^2**: When the conditional expectation function is not linear, the strength of association between the confounder U and outcome Y, treatment T can be measured by Pearson's nonparametric R^2.\n",
    "\n",
    "### Summary of the method\n",
    "\n",
    "For more details, refer to Chernozhukov et al. Long Story Short: Omitted Variable Bias in Causal Machine Learning.  https://arxiv.org/abs/2112.13398. \n",
    "\n",
    "\n",
    "We see that the bound on the bias depends on the non parametric partial R^2 of the unobserved confounders with outcome (r2yu_tw) and treatment (r2tu_w). <br>\n",
    "Partial R^2 of outcome Y with confounder U given treatment T and common causes W is given by <br>\n",
    "R2yu_tw = ( R2y_utw - R2y_tw) / ( 1 - R2y_tw ) <br>\n",
    "Similarly, R2tu_w = ( R2t_uw - R2t_w ) / ( 1 - R2t_w ) <br>\n",
    "\n",
    "AddUnobservedCommonCause class supports three methods:\n",
    "1) Simulation based <br>\n",
    "2) Linear partial R2 based : Sensitivity Analysis for linear models.<br>\n",
    "3) Non-Parametric partial R2 based : Sensitivity Analyis for non-parametric models. Two important quantities used to estimate the bias are alpha and g<br> <br>\n",
    "g := E[Y | T, W, Z] denotes the long regression function<br>\n",
    "g_s := E[Y | T, W] denotes the short regression function<br>\n",
    "α := (T - E[T | W, Z] ) / (E(T - E[T | W, Z]) ^ 2) denotes long reisz representer<br>\n",
    "α_s := (T - E[T | W] ) / (E(T - E[T | W]) ^ 2) denotes short reisz representer<br> <br>\n",
    "Bias = E(g_s - g)(α_s - α) for partially linear models<br>\n",
    "Thus, The bound is the product of additional variations that omitted confounders generate in the regression function and in the reisz representer for partially linear models.<br>\n",
    "Whereas for non parametric models, Bias = S * Cg * Calpha <br>\n",
    "where Cg and Calpha are explanatory powers of the confounder where \n",
    "- Cg^2 = r2yu_tw\n",
    "- Calpha^2 = r2tu_w / (1 - r2tu_w\n",
    "- S^2 = E(Y - g_s) ^ 2 * E(α_s ^ 2) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67b63e",
   "metadata": {},
   "source": [
    "## Step 1: Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbab4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import dowhy.datasets\n",
    "from dowhy.utils.util import create_polynomial_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c386282",
   "metadata": {},
   "source": [
    "### Step 2: Load the dataset \n",
    "We create a dataset with linear relationships between common causes and treatment, and common causes and outcome. Beta is the true causal effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c60ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101) \n",
    "data = dowhy.datasets.partially_linear_dataset(beta = 10,\n",
    "                                               num_common_causes = 7,\n",
    "                                               num_unobserved_common_causes=1,\n",
    "                                               strength_unobserved_confounding=10,\n",
    "                                               num_samples = 500,\n",
    "                                               num_treatments = 1,\n",
    "                                               stddev_treatment_noise = 10,\n",
    "                                               stddev_outcome_noise = 5\n",
    "                                                )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(data[\"df\"]['W0'], data[\"df\"]['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df879f9",
   "metadata": {},
   "source": [
    "The true ATE for this data-generating process is,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75882711",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308f4dc",
   "metadata": {},
   "source": [
    "To simulate unobserved confounding, we remove one of the common causes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b6a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observed data \n",
    "dropped_cols=[\"W0\"]\n",
    "user_data = data[\"df\"].drop(dropped_cols, axis = 1)\n",
    "# assumed graph\n",
    "user_graph = data[\"gml_graph\"]\n",
    "for col in dropped_cols:\n",
    "    user_graph = user_graph.replace('node[ id \"{0}\" label \"{0}\"]'.format(col), '')\n",
    "    user_graph = re.sub('edge\\[ source \"{}\" target \"[vy][0]*\"\\]'.format(col), \"\", user_graph)\n",
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae95e95",
   "metadata": {},
   "source": [
    "### Step 3: Create Causal Model\n",
    "Create a causal model with the \"observed\" data and causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207034e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_str = 'graph[directed 1node[ id \"y\" label \"y\"]node[ id \"W0\" label \"W0\"] node[ id \"W1\" label \"W1\"] node[ id \"W2\" label \"W2\"] node[ id \"W3\" label \"W3\"]  node[ id \"W5\" label \"W5\"] node[ id \"W6\" label \"W6\"]node[ id \"v0\" label \"v0\"]edge[source \"v0\" target \"y\"]edge[ source \"W0\" target \"v0\"] edge[ source \"W1\" target \"v0\"] edge[ source \"W2\" target \"v0\"] edge[ source \"W3\" target \"v0\"] edge[ source \"W5\" target \"v0\"] edge[ source \"W6\" target \"v0\"]edge[ source \"W0\" target \"y\"] edge[ source \"W1\" target \"y\"] edge[ source \"W2\" target \"y\"] edge[ source \"W3\" target \"y\"] edge[ source \"W5\" target \"y\"] edge[ source \"W6\" target \"y\"]]'\n",
    "model = CausalModel(\n",
    "            data=user_data,\n",
    "            treatment=data[\"treatment_name\"],\n",
    "            outcome=data[\"outcome_name\"],\n",
    "            graph=user_graph,\n",
    "            test_significance=None,\n",
    "        )\n",
    "model.view_model()\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17273bf7",
   "metadata": {},
   "source": [
    "### Step 4: Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaec5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db414ee7",
   "metadata": {},
   "source": [
    "### Step 5: Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import econml\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "estimate = model.estimate_effect(identified_estimand, \n",
    "                                    method_name=\"backdoor.econml.dml.KernelDML\",\n",
    "                                    method_params={\n",
    "                                        'init_params': {'model_y':GradientBoostingRegressor(),\n",
    "                                                        'model_t': GradientBoostingRegressor(),                                                       },\n",
    "                                        'fit_params': {},#{'cache_values': True,}\n",
    "                                     })\n",
    "print(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f62978",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate = model.estimate_effect(identified_estimand, \n",
    "                                    method_name=\"backdoor.linear_regression\",\n",
    "                                 )\n",
    "print(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffe64f",
   "metadata": {},
   "source": [
    "### Step 6: Refutation and Sensitivity Analysis\n",
    "After estimation , we need to check how robust our estimate is against the possibility of unobserved confounders. This can be done using sensitivity analysis. We perform non parametric sensitivity analysis since we do not assume the data to be linearly generated.Non parametric models make no assumption about the mapping function or distribution of the data.\n",
    "- <b>identified_estimand</b>: An instance of the identifiedEstimand class that provides the information with respect to which causal pathways are employed when the treatment effects the outcome<br>\n",
    "- <b>estimate</b>: An instance of CausalEstimate class. The estimate obtained from the estimator for the original data.<br>\n",
    "- <b>method_name</b>: Refutation method name <br>\n",
    "- <b>simulated_method_name</b>: \"non-parametric-partial-R2\" for Non Parametric Sensitivity Analysis<br>\n",
    "- <b>num_splits</b>: number of splits for cross validation. (default = 5) <br>\n",
    "- <b>shuffle_data</b> : shuffle data or not before splitting into folds (default = False)<br>\n",
    "- <b>shuffle_random_seed</b>: seed for randomly shuffling data<br>\n",
    "- <b>alpha_s_param_dict</b>: dictionary with parameters for finding alpha_s: <br>\n",
    "    - <b>reisz_functions</b>: List of polynomial functions of n degree to approximate reisz representer created using create_polynomial_function\n",
    "    - <b>l2_regularizer</b>: l2 penalty while modeling (default = 1e-3)\n",
    "    - For details of other parameters other parameters of ReiszRepresenter class see: https://econml.azurewebsites.net/_autosummary/econml.grf.CausalForest.html \n",
    "- <b>g_s_estimator_list</b>: list of estimator objects for finding g_s. Example: <br> \n",
    "[<br> RandomForestRegressor(n_estimators = 100, random_state = 120),<br> \n",
    "Pipeline([('scale', ColumnTransformer([('num', StandardScaler(), numeric_features)], remainder='passthrough')), ('lasso_model', Lasso())]),<br>\n",
    "ReiszRegressor(regression_functions = create_polynomial_function(max_degree), min_var_leaf_on_val = True,min_impurity_decrease = 1e-4, max_samples = 0.80)<br>\n",
    "]\n",
    "- <b>g_s_estimator_param_list</b>: list of dictionaries with parameters for tuning respective estimators in g_s_estimator_list. Example: <br>\n",
    "[ { 'n_estimators' : [50], \n",
    "    'max_depth' : [3, 4, 5],\n",
    "    'min_samples_leaf' : [10,50]\n",
    "  },<br>{'lasso_model__alpha' : [ 0.01, 0.001, 1e-4, 1e-5, 1e-6]},<br>\n",
    "  {'regression_functions' : [create_polynomial_function(2), create_polynomial_function(4)],\n",
    "   'min_samples_leaf' : [10, 50],\n",
    "   'min_var_fraction_leaf' : [0.01, 0.1],\n",
    "   'l2_regularizer' : [1e-2, 1e-3]\n",
    "   }<br>\n",
    "]\n",
    "    - The parameters for ReiszRegressor\n",
    "        - <b>regression_functions</b>: List of polynomial functions of n degree to approximate reisz regressor created using create_polynomial_function\n",
    "        - <b>l2_regularizer</b>: l2 penalty while modeling (default = 1e-3)\n",
    "        - For details of other parameters of ReiszRegressor class see: https://econml.azurewebsites.net/_autosummary/econml.grf.CausalForest.html \n",
    "- <b>benchmark_common_causes</b>: Name of the covariates used to bound the strengths of unobserved confounder<br>\n",
    "- <b>effect_fraction_on_treatment</b>: Strength of association between unobserved confounder and treatment compared to benchmark covariate<br>\n",
    "- <b>effect_fraction_on_outcome</b>: Strength of association between unobserved confounder and outcome compared to benchmark covariate<br>\n",
    "- <b>plot_estimate</b>: Generate contour plot for estimate while performing sensitivity analysis. (default = True). To override the setting, set plot_estimate = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e1237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refute = model.refute_estimate(identified_estimand, estimate,\n",
    "                               method_name = \"add_unobserved_common_cause\",\n",
    "                               simulated_method_name = \"non-parametric-partial-R2\",\n",
    "                               alpha_s_estimator_param_list =  None,\n",
    "                               benchmark_common_causes = [\"W1\", \"W2\", \"W3\", \"W4\", \"W5\"],\n",
    "                               effect_fraction_on_treatment = 0.2,\n",
    "                               plugin_reisz=True\n",
    "                              )\n",
    "print(refute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63007e",
   "metadata": {},
   "source": [
    "The x-axis shows (hypothetical) partial R^2 values of unobserved confounder(s) with the treatment. The y-axis shows hypothetical partial R^2 of unobserved confounder(s) with the outcome. At <x=0,y=0>, the black diamond shows the original estimate (theta_s) without considering the unobserved confounders.\n",
    "\n",
    "The contour levels represent *adjusted* lower confidence bound estimate of the effect, which would be obtained if the unobserved confounder(s) had been included in the estimation model. The red contour line is the critical threshold where the adjusted effect goes to zero. Thus,  confounders with such strength or stronger are sufficient to reverse the sign of the estimated effect and invalidate the research conclusions.\n",
    "\n",
    "The red triangle shows the estimated partial-R^2 of a chosen benchmark observed covariate with the treatment and outcome. In the above call, we chose *W3* as the benchmark covariate which has very low partial-R^2. Under the unobserved confounder cannot be stronger in its effect on treatment and outcome than the observed benchmark covariate (*W3*), the above plot shows that the mean estimated effect will stay above 8.92 even after accounting for unobserved confounding.\n",
    "\n",
    "To verify, the true causal effect can be seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute.S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156a9f2",
   "metadata": {},
   "source": [
    "##### Parameter List for plot function\n",
    "- <b>plot_type</b>: possible values are 'bias','lower_ate_bound','upper_ate_bound','lower_confidence_bound','upper_confidence_bound'<br>\n",
    "- <b>x_limit</b>: plot's maximum x_axis value (default = 0.8) <br>\n",
    "- <b>y_limit</b>: plot's minimum y_axis value (default = 0.8) <br>\n",
    "- <b>num_points_per_contour</b>: number of points to calculate and plot each contour line (default = 200) <br>\n",
    "- <b>plot_size</b>: tuple denoting the size of the plot (default = (7,7))<br>\n",
    "- <b>contours_color</b>: color of contour line (default = blue)<br>\n",
    "String or array. If array, lines will be plotted with the specific color in ascending order.<br>\n",
    "- <b>critical_contour_color</b>: color of threshold line (default = red)<br>\n",
    "- <b>label_fontsize</b>: fontsize for labelling contours (default = 9)<br>\n",
    "- <b>contour_linewidths</b>: linewidths for contours (default = 0.75)<br>\n",
    "- <b>contour_linestyles</b>: linestyles for contours (default = \"solid\") See : https://matplotlib.org/3.5.0/gallery/lines_bars_and_markers/linestyles.html<br>\n",
    "- <b>contours_label_color</b>: color of contour line label (default = black)<br>\n",
    "- <b>critical_label_color</b>: color of threshold line label (default = red)<br>\n",
    "- <b>unadjusted_estimate_marker</b>: marker type for unadjusted estimate in the plot (default = 'D')\n",
    "See: https://matplotlib.org/stable/api/markers_api.html <br>\n",
    "- <b>unadjusted_estimate_color</b>: marker color for unadjusted estimate in the plot (default = \"black\")<br>\n",
    "- <b>adjusted_estimate_marker</b>: marker type for bias adjusted estimates in the plot (default = '^')<br>\n",
    "- <b>adjusted_estimate_color</b>: marker color for bias adjusted estimates in the plot (default = \"red\")<br>\n",
    "- <b>legend_position</b>:tuple denoting the position of the legend (default = (1.6, 0.6))<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute.plot(plot_type = \"upper_ate_bound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28eddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute.plot(plot_type = \"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da66c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d86c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a5292",
   "metadata": {},
   "source": [
    "The robustness value measures the minimal equal strength of r2yu_tw and r2tu_w such the bound for the average treatment effect would include zero. It can be between 0 and 1.<br>\n",
    "A low robustness value implies that the results can be changed even by the presence of weak confounders whereas a robustness value close to 1 means the treatment effect can handle strong confounders explaining  almost all residual variation of the treatment and the outcome.\n",
    "A robustness value of 0.68 implies that confounders with r2yu_tw and r2tu_w values less than 0.68 would not be sufficient enough to bring down the estimates to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891068cb",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis for Partially Linear Models\n",
    "Partially Linear Models are where the conditional expectation functions (CEF) of the outcome are linearly separable in the treatment.<br>\n",
    "Here, we perform partial sensitivity analysis for LinearDML estimator from econml. This method is computationally faster.<br>\n",
    "The first four steps are common:<br>\n",
    "1. Load Packages\n",
    "2. Load Dataset\n",
    "3. Create Causal Model\n",
    "4. Identification\n",
    "\n",
    "### Step 5: Estimation\n",
    "Partial Linear Sensitivity Analysis is aperformed automatically if LinearDML estimator from econml is used for estimation.<br>\n",
    " Set <b>cache_values</b> = <b>True</b> in fit_params to cache the results of first stage estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import econml\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "dml_estimate = model.estimate_effect(identified_estimand, \n",
    "                                    method_name=\"backdoor.econml.dml.LinearDML\",\n",
    "                                    method_params={\n",
    "                                        'init_params': {'model_y':GradientBoostingRegressor(),\n",
    "                                                        'model_t': GradientBoostingRegressor(),\n",
    "                                                        'linear_first_stages': False\n",
    "                                                       },\n",
    "                                        'fit_params': {'cache_values': True,}\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute2 = model.refute_estimate(identified_estimand, dml_estimate ,\n",
    "                               method_name = \"add_unobserved_common_cause\",\n",
    "                               simulated_method_name = \"non-parametric-partial-R2\",\n",
    "                               benchmark_common_causes = [\"W1\"],\n",
    "                               effect_fraction_on_treatment = 0.05,\n",
    "                                effect_fraction_on_ouctome = 0.04\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce6ab2",
   "metadata": {},
   "source": [
    "The x axis shows hypothetical partial R2 values of unobserved confounder(s) with the treatment. The y axis shows hypothetical partial R2 of unobserved confounder(s) with the outcome.<br>\n",
    "The contour levels represent adjusted lower confidence bound for unobserved confounders with hypothetical partialR2 values when these would be included in full regression model. <br>\n",
    "The black diamond shows the original estimate (theta_s) without considering the unobserved confounders<br>\n",
    "The red line is the critical threshold: confounders with such strength or stronger are sufficient to invalidate the research conclusions.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934eef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute2.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "refute2.RV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3524cb07",
   "metadata": {},
   "source": [
    "The robustness value measures the minimal equal strength of r2yu_tw and r2tu_w such the bound for the average treatment effect would include zero. <br>\n",
    "A robustness value of 0.4 implies that confounders with r2yu_tw and r2tu_w values less than 0.4 would not be sufficient enough to bring down the estimates to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refute2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744411e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6fa83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
